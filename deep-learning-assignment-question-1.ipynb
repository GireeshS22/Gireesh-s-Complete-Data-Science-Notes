{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### Step 1: Import Libraries/Dataset (0 mark)","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if np.random.random() < 0.005: print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-12-24T12:38:55.739115Z","iopub.execute_input":"2021-12-24T12:38:55.740182Z","iopub.status.idle":"2021-12-24T12:38:58.282978Z","shell.execute_reply.started":"2021-12-24T12:38:55.740129Z","shell.execute_reply":"2021-12-24T12:38:58.282054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport cv2\n\n# example of horizontal shift image augmentation\nfrom numpy import expand_dims\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom matplotlib import pyplot\n\n# Keras Libraries\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom sklearn.metrics import classification_report, confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:38:58.285126Z","iopub.execute_input":"2021-12-24T12:38:58.28555Z","iopub.status.idle":"2021-12-24T12:38:58.293745Z","shell.execute_reply.started":"2021-12-24T12:38:58.285499Z","shell.execute_reply":"2021-12-24T12:38:58.2924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Data Visualization and augmentation (1 mark)\n","metadata":{}},{"cell_type":"code","source":"images = ['/kaggle/input/chest-xray-pneumonia/chest_xray/train/NORMAL/IM-0219-0001.jpeg',\n         '/kaggle/input/chest-xray-pneumonia/chest_xray/train/PNEUMONIA/person1242_virus_2109.jpeg']\n\nfor imgs in images:\n    # load the image\n    img = load_img(imgs)\n\n    # convert to numpy array\n    data = img_to_array(img)\n    \n    # expand dimension to one sample\n    samples = expand_dims(data, 0)\n    image = samples[0].astype('uint8')\n\n    pyplot.imshow(image)\n    # show the figure\n    pyplot.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:38:58.295423Z","iopub.execute_input":"2021-12-24T12:38:58.295803Z","iopub.status.idle":"2021-12-24T12:38:59.05581Z","shell.execute_reply.started":"2021-12-24T12:38:58.295756Z","shell.execute_reply":"2021-12-24T12:38:59.054912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# load the image\nimg = load_img('/kaggle/input/chest-xray-pneumonia/chest_xray/train/NORMAL/IM-0219-0001.jpeg')\n\n# convert to numpy array\ndata = img_to_array(img)\n\n# expand dimension to one sample\nsamples = expand_dims(data, 0)\n\n# create image data augmentation generator\ndatagen = ImageDataGenerator(width_shift_range=[-200,200])\n\n# prepare iterator\nit = datagen.flow(samples, batch_size=1)\n\n# generate samples and plot\nfor i in range(9):\n    # define subplot\n    pyplot.subplot(330 + 1 + i)\n    # generate batch of images\n    batch = it.next()\n    # convert to unsigned integers for viewing\n    image = batch[0].astype('uint8')\n    # plot raw pixel data\n    pyplot.imshow(image)\n# show the figure\npyplot.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:38:59.057638Z","iopub.execute_input":"2021-12-24T12:38:59.05812Z","iopub.status.idle":"2021-12-24T12:39:05.056018Z","shell.execute_reply.started":"2021-12-24T12:38:59.058072Z","shell.execute_reply":"2021-12-24T12:39:05.055043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the image\nimg = load_img('/kaggle/input/chest-xray-pneumonia/chest_xray/train/NORMAL/IM-0219-0001.jpeg')\n# convert to numpy array\ndata = img_to_array(img)\n# expand dimension to one sample\nsamples = expand_dims(data, 0)\n# create image data augmentation generator\ndatagen = ImageDataGenerator(height_shift_range=0.5)\n# prepare iterator\nit = datagen.flow(samples, batch_size=1)\n# generate samples and plot\nfor i in range(9):\n    # define subplot\n    pyplot.subplot(330 + 1 + i)\n    # generate batch of images\n    batch = it.next()\n    # convert to unsigned integers for viewing\n    image = batch[0].astype('uint8')\n    # plot raw pixel data\n    pyplot.imshow(image)\n    # show the figure\npyplot.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:39:05.060322Z","iopub.execute_input":"2021-12-24T12:39:05.060561Z","iopub.status.idle":"2021-12-24T12:39:10.643761Z","shell.execute_reply.started":"2021-12-24T12:39:05.06053Z","shell.execute_reply":"2021-12-24T12:39:10.642754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the image\nimg = load_img('/kaggle/input/chest-xray-pneumonia/chest_xray/train/NORMAL/IM-0219-0001.jpeg')\n# convert to numpy array\ndata = img_to_array(img)\n# expand dimension to one sample\nsamples = expand_dims(data, 0)\n# create image data augmentation generator\ndatagen = ImageDataGenerator(rotation_range=90)\n# prepare iterator\nit = datagen.flow(samples, batch_size=1)\n# generate samples and plot\nfor i in range(9):\n    # define subplot\n    pyplot.subplot(330 + 1 + i)\n    # generate batch of images\n    batch = it.next()\n    # convert to unsigned integers for viewing\n    image = batch[0].astype('uint8')\n    # plot raw pixel data\n    pyplot.imshow(image)\n# show the figure\npyplot.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:39:10.645304Z","iopub.execute_input":"2021-12-24T12:39:10.645782Z","iopub.status.idle":"2021-12-24T12:39:17.129037Z","shell.execute_reply.started":"2021-12-24T12:39:10.645737Z","shell.execute_reply":"2021-12-24T12:39:17.128082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the image\nimg = load_img('/kaggle/input/chest-xray-pneumonia/chest_xray/train/NORMAL/IM-0219-0001.jpeg')\n# convert to numpy array\ndata = img_to_array(img)\n# expand dimension to one sample\nsamples = expand_dims(data, 0)\n# create image data augmentation generator\ndatagen = ImageDataGenerator(brightness_range=[0.2,1.0])\n# prepare iterator\nit = datagen.flow(samples, batch_size=1)\n# generate samples and plot\nfor i in range(9):\n    # define subplot\n    pyplot.subplot(330 + 1 + i)\n    # generate batch of images\n    batch = it.next()\n    # convert to unsigned integers for viewing\n    image = batch[0].astype('uint8')\n    # plot raw pixel data\n    pyplot.imshow(image)\n# show the figure\npyplot.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:39:17.130685Z","iopub.execute_input":"2021-12-24T12:39:17.131145Z","iopub.status.idle":"2021-12-24T12:39:20.437879Z","shell.execute_reply.started":"2021-12-24T12:39:17.131099Z","shell.execute_reply":"2021-12-24T12:39:20.437007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**References:**\n1. https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/","metadata":{}},{"cell_type":"code","source":"train_folder= '/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/train/'\ntest_folder = '/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/test/'","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:39:20.439754Z","iopub.execute_input":"2021-12-24T12:39:20.440353Z","iopub.status.idle":"2021-12-24T12:39:20.4449Z","shell.execute_reply.started":"2021-12-24T12:39:20.440308Z","shell.execute_reply":"2021-12-24T12:39:20.443919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Model Building (0.2*5 = 1 mark)**","metadata":{"execution":{"iopub.status.busy":"2021-12-24T05:56:07.036627Z","iopub.execute_input":"2021-12-24T05:56:07.037038Z","iopub.status.idle":"2021-12-24T05:56:07.041946Z","shell.execute_reply.started":"2021-12-24T05:56:07.037Z","shell.execute_reply":"2021-12-24T05:56:07.040912Z"}}},{"cell_type":"code","source":"#code from https://www.kaggle.com/rafetcan/pneumonia-normal-cnn-model\n\nimport cv2\ndef picture_separation(folder):\n    \n    '''divide the mixed pictures into NORMAL and PNEUMONIA & add labels to these'''\n    \n    X = []\n    y = []\n    image_list = []\n\n    for foldername in os.listdir(folder):\n        if not foldername.startswith('.'):\n            if foldername == \"NORMAL\":\n                label = 0\n            elif foldername == \"PNEUMONIA\":\n                label = 1\n            else:\n                label = 2\n                \n            for image_filename in os.listdir(folder + \"/\"+ foldername):\n                img_file = cv2.imread(folder + \"/\" + foldername + '/' + image_filename,0)               \n                \n\n                if img_file is not None:\n                    img = cv2.resize(img_file,(64,64))\n                    img_arr = img_to_array(img) / 255\n                    X.append(img_arr)\n                    y.append(label)\n                    image_list.append(foldername + '/' + image_filename)\n                                        \n    X = np.asarray(X)\n    y = np.asarray(y)\n    \n    return X, y, image_list","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:39:20.446716Z","iopub.execute_input":"2021-12-24T12:39:20.447406Z","iopub.status.idle":"2021-12-24T12:39:20.459907Z","shell.execute_reply.started":"2021-12-24T12:39:20.447332Z","shell.execute_reply":"2021-12-24T12:39:20.458687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get train dataset\nX_train, y_train, img_train = picture_separation(train_folder)\n\ntrain_df = pd.DataFrame(img_train, columns = [\"images\"])\ntrain_df[\"target\"] = y_train\n\n#preview\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:39:20.461308Z","iopub.execute_input":"2021-12-24T12:39:20.461536Z","iopub.status.idle":"2021-12-24T12:40:18.166589Z","shell.execute_reply.started":"2021-12-24T12:39:20.461507Z","shell.execute_reply":"2021-12-24T12:40:18.16564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get test dataset\nX_test, y_test, img_test = picture_separation(test_folder)\n\ntest_df = pd.DataFrame(img_test, columns = [\"images\"])\ntest_df[\"target\"] = y_test\n\n#preview\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:40:18.168064Z","iopub.execute_input":"2021-12-24T12:40:18.168934Z","iopub.status.idle":"2021-12-24T12:40:24.271819Z","shell.execute_reply.started":"2021-12-24T12:40:18.168879Z","shell.execute_reply":"2021-12-24T12:40:24.270874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merge to get full dataset\nfull_data = pd.concat([train_df, test_df], axis = 0, ignore_index = True)\nfull_data.info()\n\nX_train = X_train.reshape(5216, 64*64).astype('float32')\nX_test = X_test.reshape(624, 64*64).astype('float32')","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:40:24.276512Z","iopub.execute_input":"2021-12-24T12:40:24.27736Z","iopub.status.idle":"2021-12-24T12:40:24.341896Z","shell.execute_reply.started":"2021-12-24T12:40:24.277314Z","shell.execute_reply":"2021-12-24T12:40:24.340887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras import models\nfrom keras import layers\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n#initiate\nmlp_model = models.Sequential()\n\n#mulilayers with relu activation\nmlp_model.add(Dense(32, activation = 'relu', input_shape = (4096,)))\nmlp_model.add(Dense(32, activation = 'relu'))\nmlp_model.add(Dense(64, activation = 'relu'))\nmlp_model.add(Dense(128, activation = 'relu'))\n\n#one layer with sigmoid activation \nmlp_model.add(Dense(1, activation = 'sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:40:24.347501Z","iopub.execute_input":"2021-12-24T12:40:24.353568Z","iopub.status.idle":"2021-12-24T12:40:24.672537Z","shell.execute_reply.started":"2021-12-24T12:40:24.353371Z","shell.execute_reply":"2021-12-24T12:40:24.671343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import optimizers\n\nmlp_model.compile(loss = 'binary_crossentropy',\n                  optimizer = 'adam',\n                  metrics = ['acc'])\nmlp_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:40:24.677319Z","iopub.execute_input":"2021-12-24T12:40:24.677664Z","iopub.status.idle":"2021-12-24T12:40:24.6985Z","shell.execute_reply.started":"2021-12-24T12:40:24.677632Z","shell.execute_reply":"2021-12-24T12:40:24.697577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils.vis_utils import plot_model\n\n#plot\nplot_model(mlp_model, to_file = 'mlp_model_plot.png', show_shapes = True, show_layer_names = True)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:40:24.701154Z","iopub.execute_input":"2021-12-24T12:40:24.701489Z","iopub.status.idle":"2021-12-24T12:40:24.933307Z","shell.execute_reply.started":"2021-12-24T12:40:24.701436Z","shell.execute_reply":"2021-12-24T12:40:24.932133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mlp_history = mlp_model.fit(X_train, y_train,\n                            epochs = 3,\n                            batch_size = 32,\n                            validation_data = (X_test, y_test),\n                            validation_steps = 624 // 32)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:40:24.937362Z","iopub.execute_input":"2021-12-24T12:40:24.93763Z","iopub.status.idle":"2021-12-24T12:40:46.06831Z","shell.execute_reply.started":"2021-12-24T12:40:24.937596Z","shell.execute_reply":"2021-12-24T12:40:46.067259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\n\n\nfig , ax = plt.subplots(1,2)\nfig.set_size_inches(20, 8)\n\nmlp_train_acc = mlp_history.history['acc']\nmlp_train_loss = mlp_history.history['loss']\nmlp_val_acc = mlp_history.history['val_acc']\nmlp_val_loss = mlp_history.history['val_loss']\n\nepochs = range(1, len(mlp_train_acc) + 1)\n\nax[0].plot(epochs , mlp_train_acc , 'g-o' , label = 'Training Accuracy')\nax[0].plot(epochs , mlp_val_acc , 'y-o' , label = 'Validation Accuracy')\nax[0].set_title('MLP Model Training & Validation Accuracy')\nax[0].legend(loc = 'lower right')\nax[0].set_xlabel(\"Epochs\")\nax[0].set_ylabel(\"Accuracy\")\n\nax[1].plot(epochs , mlp_train_loss , 'g-o' , label = 'Training Loss')\nax[1].plot(epochs , mlp_val_loss , 'y-o' , label = 'Validation Loss')\nax[1].set_title('MLP Model Training & Validation Loss')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nax[1].set_ylabel(\"Loss\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:40:46.070448Z","iopub.execute_input":"2021-12-24T12:40:46.070788Z","iopub.status.idle":"2021-12-24T12:40:46.551845Z","shell.execute_reply.started":"2021-12-24T12:40:46.07075Z","shell.execute_reply":"2021-12-24T12:40:46.550908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\npreds = mlp_model.predict(X_test)\n\nmodel_acc = accuracy_score(y_test, np.round(preds))*100\ncm = confusion_matrix(y_test, np.round(preds))\ntn, fp, fn, tp = cm.ravel()\n\nprint('CONFUSION MATRIX')\nplt.figure()\nplot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.show()\n\nprint('\\nTESTING METRICS')\nprecision = tp/(tp+fp)*100\nrecall = tp/(tp+fn)*100\nprint('Accuracy: {}%'.format(model_acc))\nprint('Precision: {}%'.format(precision))\nprint('F1-score: {}'.format(2*precision*recall/(precision+recall)))\nprint('Recall: {}%'.format(recall))\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:40:46.553762Z","iopub.execute_input":"2021-12-24T12:40:46.554461Z","iopub.status.idle":"2021-12-24T12:40:46.855105Z","shell.execute_reply.started":"2021-12-24T12:40:46.554399Z","shell.execute_reply":"2021-12-24T12:40:46.854068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Trying a CNN model","metadata":{}},{"cell_type":"code","source":"# let's build the CNN model\ncnn = Sequential()\n#Convolution\ncnn.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(64, 64, 3)))\n#Pooling\ncnn.add(MaxPooling2D(pool_size = (2, 2)))\n# 2nd Convolution\ncnn.add(Conv2D(32, (3, 3), activation=\"relu\"))\n# 2nd Pooling layer\ncnn.add(MaxPooling2D(pool_size = (2, 2)))\n# Flatten the layer\ncnn.add(Flatten())\n# Fully Connected Layers\ncnn.add(Dense(activation = 'relu', units = 128))\ncnn.add(Dense(activation = 'sigmoid', units = 1))\n\n# Compile the Neural network\ncnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:40:46.85682Z","iopub.execute_input":"2021-12-24T12:40:46.85712Z","iopub.status.idle":"2021-12-24T12:40:46.923117Z","shell.execute_reply.started":"2021-12-24T12:40:46.85709Z","shell.execute_reply":"2021-12-24T12:40:46.92207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train \nos.listdir(train_folder)\ntrain_n = train_folder+'NORMAL/'\ntrain_p = train_folder+'PNEUMONIA/'","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:40:46.92507Z","iopub.execute_input":"2021-12-24T12:40:46.925427Z","iopub.status.idle":"2021-12-24T12:40:46.933131Z","shell.execute_reply.started":"2021-12-24T12:40:46.925367Z","shell.execute_reply":"2021-12-24T12:40:46.931956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\n\n#Normal pic \nprint(len(os.listdir(train_n)))\nrand_norm= np.random.randint(0,len(os.listdir(train_n)))\nnorm_pic = os.listdir(train_n)[rand_norm]\nprint('normal picture title: ',norm_pic)\n\nnorm_pic_address = train_n+norm_pic\n\n#Pneumonia\nrand_p = np.random.randint(0,len(os.listdir(train_p)))\n\nsic_pic =  os.listdir(train_p)[rand_norm]\nsic_address = train_p+sic_pic\nprint('pneumonia picture title:', sic_pic)\n\n# Load the images\nnorm_load = Image.open(norm_pic_address)\nsic_load = Image.open(sic_address)\n\n#Let's plt these images\nf = plt.figure(figsize= (10,6))\na1 = f.add_subplot(1,2,1)\nimg_plot = plt.imshow(norm_load)\na1.set_title('Normal')\n\na2 = f.add_subplot(1, 2, 2)\nimg_plot = plt.imshow(sic_load)\na2.set_title('Pneumonia')","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:40:46.934939Z","iopub.execute_input":"2021-12-24T12:40:46.93539Z","iopub.status.idle":"2021-12-24T12:40:47.854428Z","shell.execute_reply.started":"2021-12-24T12:40:46.935306Z","shell.execute_reply":"2021-12-24T12:40:47.853391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1./255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1./255)  #Image normalization.\n\ntraining_set = train_datagen.flow_from_directory(train_folder,\n                                                 target_size = (64, 64),\n                                                 batch_size = 32,\n                                                 class_mode = 'binary')\n\ntest_set = test_datagen.flow_from_directory(test_folder,\n                                            target_size = (64, 64),\n                                            batch_size = 32,\n                                            class_mode = 'binary')","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:40:47.856733Z","iopub.execute_input":"2021-12-24T12:40:47.857069Z","iopub.status.idle":"2021-12-24T12:40:48.824918Z","shell.execute_reply.started":"2021-12-24T12:40:47.857015Z","shell.execute_reply":"2021-12-24T12:40:48.823948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:40:48.826495Z","iopub.execute_input":"2021-12-24T12:40:48.827574Z","iopub.status.idle":"2021-12-24T12:40:48.842895Z","shell.execute_reply.started":"2021-12-24T12:40:48.827527Z","shell.execute_reply":"2021-12-24T12:40:48.841543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_model = cnn.fit_generator(training_set,\n                         steps_per_epoch = 163,\n                         epochs = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T12:40:48.844452Z","iopub.execute_input":"2021-12-24T12:40:48.844965Z","iopub.status.idle":"2021-12-24T13:01:31.297069Z","shell.execute_reply.started":"2021-12-24T12:40:48.844917Z","shell.execute_reply":"2021-12-24T13:01:31.296023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_accu = cnn.evaluate_generator(test_set,steps=624)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T13:01:31.29888Z","iopub.execute_input":"2021-12-24T13:01:31.299607Z","iopub.status.idle":"2021-12-24T13:01:37.482601Z","shell.execute_reply.started":"2021-12-24T13:01:31.299546Z","shell.execute_reply":"2021-12-24T13:01:37.481539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The testing accuracy is :',test_accu[1]*100, '%')","metadata":{"execution":{"iopub.status.busy":"2021-12-24T13:01:37.484171Z","iopub.execute_input":"2021-12-24T13:01:37.484911Z","iopub.status.idle":"2021-12-24T13:01:37.492903Z","shell.execute_reply.started":"2021-12-24T13:01:37.484859Z","shell.execute_reply":"2021-12-24T13:01:37.491716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred = cnn.predict_generator(test_set, 100)\ny_pred = np.argmax(Y_pred, axis=1)\nconfusion_matrix(test_set.classes, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T13:01:37.494961Z","iopub.execute_input":"2021-12-24T13:01:37.495781Z","iopub.status.idle":"2021-12-24T13:01:43.312874Z","shell.execute_reply.started":"2021-12-24T13:01:37.495733Z","shell.execute_reply":"2021-12-24T13:01:43.31191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy \nplt.plot(cnn_model.history['accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Training set', 'Validation set'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T13:01:43.31474Z","iopub.execute_input":"2021-12-24T13:01:43.315137Z","iopub.status.idle":"2021-12-24T13:01:43.579873Z","shell.execute_reply.started":"2021-12-24T13:01:43.315093Z","shell.execute_reply":"2021-12-24T13:01:43.578904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loss \n\nplt.plot(cnn_model.history['loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Training set', 'Test set'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T13:01:43.581432Z","iopub.execute_input":"2021-12-24T13:01:43.582369Z","iopub.status.idle":"2021-12-24T13:01:43.832065Z","shell.execute_reply.started":"2021-12-24T13:01:43.582303Z","shell.execute_reply":"2021-12-24T13:01:43.830929Z"},"trusted":true},"execution_count":null,"outputs":[]}]}